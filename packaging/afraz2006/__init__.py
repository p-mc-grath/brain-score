import logging
import math
import shutil
from pathlib import Path

import numpy as np
import pandas as pd
from PIL import Image
from numpy.random.mtrand import RandomState
from tqdm import tqdm

from brainio.assemblies import DataAssembly
from brainio.stimuli import StimulusSet

logger = logging.getLogger(__name__)

source_face_directory = Path('/braintree/data2/active/common/labeled_faces_in_the_wild/')
source_imagenet_directory = Path('/braintree/data2/active/common/imagenet_raw/train')
source_imagenet_synsets = [  # from https://gist.github.com/fnielsen/4a5c94eaa6dcdf29b7a62d886f540372
    # object synsets that will hopefully not have faces in them
    'n03376595',  # folding chair
    'n07753275',  # pineapple
    'n02321529',  # sea cucumber
    'n02974003',  # car wheel
    'n03792782',  # mountain bike
]

data_directory = Path(__file__).parent

FACE_LABEL = 'face'
NONFACE_LABEL = 'nonface'


# from Afraz et al., Nature 2006:
# "The images were greyscale photographs of 30 face objects and 60 non-face objects chosen randomly
# from a bank of 600 images."
# "In the categorization task, 11 or 9 signal levels were used in monkey FR and 9 signal levels were used in monkey KH.
# Each signal level was generated by assigning a uniformly distributed greyscale value to X% of image pixels,
# where X is the absolute signal level (positive for faces and negative for non-faces).
# Noisy face and non-face images create a continuum of task relevant visual signal extending
# from noiseless faces (100) to full noise images (0) to noiseless non- faces (-100).
# For each signal level, 16 face and 16 non-face images were randomly selected from the image bank."
#
# Interpretation: there are a total of 600 base (non-noisy) images, 30 + 60 = 90 of which are used for testing.
# This presumably leaves 600 - 90 = 510 images for training, but it is unclear how training noise levels were decided.
# From visual inspection, it seems the signal levels are:
#   -50, -40, -25, -15, 0, 15, 25, 40, 50 for monkey KH, and
#   -80, -50, -40, -25, -15, 0, 15, 25, 40, 50, 80 for monkey FR
# The signs on the signal levels are likely only there for the sake of writing, since 16 face + 16 non-face images are
# sampled per signal level, the corresponding signal levels should be (0, 15, 25, 40, 50).
# We will use the full extent of noise levels (i.e. 0, 15, 25, 40, 50), giving us 6 * (16 + 16) = 192 test images.
# For training, we will sample 135 face and 135 non-face images per level, giving us 6 * (67 + 67) = 804 train images.


def train_test_stimuli(size_image_bank=600,
                       number_of_test_faces=30, number_of_test_nonfaces=60,
                       signal_levels=(0, 15, 25, 40, 50, 80),
                       test_faces_per_level=16, test_nonfaces_per_level=16,
                       train_faces_per_level=67, train_nonfaces_per_level=67,
                       ):
    logger.info(f"Collecting {size_image_bank} base images")
    face_paths, nonface_paths = collect_stimuli(num_images=size_image_bank)
    face_paths, nonface_paths = list(sorted(face_paths)), list(sorted(nonface_paths))
    # convert to StimulusSet
    image_ids = [path.stem for path in face_paths + nonface_paths]
    image_bank = StimulusSet({'image_id': image_ids,
                              'image_label': [FACE_LABEL] * len(face_paths) + [NONFACE_LABEL] * len(nonface_paths)})
    image_bank.image_paths = dict(zip(image_ids, face_paths + nonface_paths))
    image_bank.identifier = 'faces_nonfaces'
    # downsample
    logger.info("Downsampling")
    image_bank = downsample(image_bank)
    # convert to grayscale
    logger.info("Converting to grayscale")
    image_bank = make_grayscale(image_bank)
    # choose 30 face and 60 non-face objects for testing
    logger.info(f"Splitting {number_of_test_faces} (face) + {number_of_test_nonfaces} (nonface) test images")
    test_stimuli = select_test_stimuli(image_bank, num_faces=number_of_test_faces, num_nonfaces=number_of_test_nonfaces)
    train_stimuli = image_bank[~image_bank['image_id'].isin(test_stimuli['image_id'])]
    test_stimuli.identifier += '-test'
    train_stimuli.identifier += '-train'
    # add noise
    logger.info(f"Adding noise: {signal_levels} x ({test_faces_per_level} + {test_nonfaces_per_level})")
    noisy_test_stimuli = make_noisy(stimuli=test_stimuli, signal_levels=signal_levels,
                                    faces_per_level=test_faces_per_level, nonfaces_per_level=test_nonfaces_per_level)
    assert len(noisy_test_stimuli) == len(signal_levels) * (test_faces_per_level + test_nonfaces_per_level) == 192
    logger.info(f"Adding noise: {signal_levels} x ({train_faces_per_level} + {train_nonfaces_per_level})")
    noisy_train_stimuli = make_noisy(stimuli=train_stimuli, signal_levels=signal_levels,
                                     faces_per_level=train_faces_per_level, nonfaces_per_level=train_nonfaces_per_level)
    assert len(noisy_train_stimuli) == len(signal_levels) * (train_faces_per_level + train_nonfaces_per_level) == 804
    return noisy_train_stimuli, noisy_test_stimuli


def collect_stimuli(num_images: int, face_nonface_ratio: float = 0.5):
    # get desired number of paths
    num_faces = int(num_images * face_nonface_ratio)
    num_nonfaces = num_images - num_faces
    faces = sample_faces(num_faces)
    nonfaces = sample_nonfaces(num_nonfaces)
    # copy into working directory
    faces_local = copy_paths(faces, data_directory / 'faces')
    nonfaces_local = copy_paths(nonfaces, data_directory / 'nonfaces')
    return faces_local, nonfaces_local


def select_test_stimuli(image_bank: StimulusSet, num_faces: int, num_nonfaces: int) -> StimulusSet:
    face_ids = image_bank['image_id'][image_bank['image_label'] == FACE_LABEL]
    nonface_ids = image_bank['image_id'][image_bank['image_label'] == NONFACE_LABEL]
    random_state = RandomState(1)
    test_face_ids = random_state.choice(face_ids, size=num_faces, replace=False)
    test_nonface_ids = random_state.choice(nonface_ids, size=num_nonfaces, replace=False)
    test_stimuli = image_bank[image_bank['image_id'].isin(np.concatenate((test_face_ids, test_nonface_ids)))]
    return test_stimuli


def make_noisy(stimuli: StimulusSet, signal_levels, faces_per_level: int, nonfaces_per_level: int,
               skip_if_exist=True) -> StimulusSet:
    """
    For each signal level, sample a number of face and non-face images, and alter them based on the noise level
    """
    identifier = stimuli.identifier + f'-noisy_{len(signal_levels)}x{faces_per_level}_{nonfaces_per_level}'
    noisy_stimuli, noisy_paths = [], []
    target_directory = data_directory / identifier
    target_directory.mkdir(exist_ok=True)
    # only allow skipping file creation if exact same number of files in target directory
    expected_num_images = len(signal_levels) * (faces_per_level + nonfaces_per_level)
    skip_if_exist = skip_if_exist and len(list(target_directory.iterdir())) == expected_num_images
    random_state_ids = RandomState(seed=1)
    random_state_noise = RandomState(seed=1)

    for signal_level in tqdm(signal_levels, desc='noise'):
        noise_level = 1 - signal_level / 100
        # sample a number of face and non-face images per noise level
        face_ids = random_state_ids.choice(stimuli['image_id'][stimuli['image_label'] == FACE_LABEL],
                                           faces_per_level, replace=False)
        nonface_ids = random_state_ids.choice(stimuli['image_id'][stimuli['image_label'] == NONFACE_LABEL],
                                              nonfaces_per_level, replace=False)

        for image_id in np.concatenate((face_ids, nonface_ids)):  # perturb all chosen images
            source_path = stimuli.get_image(image_id)
            noisy_image_id = image_id + f'-signal{signal_level}'
            target_path = target_directory / (source_path.stem + f'-signal{signal_level}' + source_path.suffix)
            if skip_if_exist:
                assert target_path.is_file()
                # if expecting skip, assume that the file was created under the exact same conditions and re-use
            else:
                image = Image.open(source_path)
                noisy_image = make_noisy_image(np.array(image), noise_level=noise_level,
                                               random_state=random_state_noise)
                noisy_image = Image.fromarray(noisy_image)
                noisy_image.save(target_path)
            image_meta = stimuli[stimuli['image_id'] == image_id]
            assert len(image_meta) == 1
            stimulus_row = {**image_meta.iloc[0].to_dict(),
                            **{'signal_level': signal_level, 'noise_level': noise_level}}
            stimulus_row['image_id'] = noisy_image_id
            noisy_stimuli.append(stimulus_row)
            noisy_paths.append(target_path)

    # put everything together in a StimulusSet
    noisy_stimuli = StimulusSet(noisy_stimuli)
    signal_direction = [-1 if label == NONFACE_LABEL else +1 for label in noisy_stimuli['image_label']]
    noisy_stimuli['label_signal_level'] = signal_direction * noisy_stimuli['signal_level']
    noisy_stimuli.image_paths = dict(zip(noisy_stimuli['image_id'], noisy_paths))
    noisy_stimuli.identifier = identifier
    return noisy_stimuli


def make_noisy_image(image, noise_level, random_state):
    shape = image.shape
    assert len(shape) == 2
    noise_mask = random_state.choice(a=[True, False], size=np.prod(shape), p=[noise_level, 1 - noise_level])
    noise = random_state.uniform(low=0, high=255, size=sum(noise_mask))
    image = image.reshape(-1)
    image[noise_mask] = noise
    image = image.reshape(shape)
    return image


def lopsided_sample(size=None, lam=.5):
    sample = np.random.poisson(lam=lam, size=size)
    clip_max = 5
    sample = np.clip(sample, a_min=None, a_max=clip_max)
    sample = sample / clip_max
    return sample


def sample_faces(num_images):
    # faces are not uniformly distributed
    directories = list(source_face_directory.iterdir())
    num_directories = len(directories)
    images_per_directory = math.ceil(num_images / num_directories)
    paths = []
    random_state = RandomState(1)
    for directory in directories:
        if len(set(paths)) == num_images:
            break
        directory_paths = list((source_face_directory / directory).iterdir())
        paths += [source_face_directory / directory / filename for filename in random_state.choice(
            # since some directories have only one image, we need to allow replacement
            directory_paths, images_per_directory, replace=True)]
    paths = list(sorted(set(paths)))  # get rid of duplicates
    return paths


def sample_nonfaces(num_images):
    # uniform distribution of images
    paths = [source_imagenet_directory / synset / path for synset in source_imagenet_synsets
             for path in (source_imagenet_directory / synset).iterdir()]
    random_state = RandomState(1)
    return random_state.choice(paths, num_images, replace=False)


def make_grayscale(stimulus_set: StimulusSet) -> StimulusSet:
    stimulus_set_grayscale = stimulus_set.copy()
    for image_id in tqdm(stimulus_set_grayscale['image_id'], desc='make grayscale'):
        path = stimulus_set_grayscale.get_image(image_id)
        image = Image.open(path)
        directory_grayscale = Path(str(path.parent) + '-grayscale')
        directory_grayscale.mkdir(exist_ok=True)
        path_grayscale = directory_grayscale / (path.stem + '-grayscale' + path.suffix)
        if not path_grayscale.is_file():  # only convert and save if needed
            image_grayscale = image.convert('L')
            image_grayscale.save(path_grayscale)
        stimulus_set_grayscale.image_paths[image_id] = path_grayscale
    stimulus_set_grayscale.identifier += '-grayscale'
    return stimulus_set_grayscale


def downsample(stimulus_set: StimulusSet, downsample_size=64) -> StimulusSet:
    stimulus_set_downsample = stimulus_set.copy()
    for image_id in tqdm(stimulus_set_downsample['image_id'], desc='downsample'):
        path = stimulus_set_downsample.get_image(image_id)
        image = Image.open(path)
        directory_downsample = Path(str(path.parent) + '-downsample')
        directory_downsample.mkdir(exist_ok=True)
        path_downsample = directory_downsample / (path.stem + '-downsample' + path.suffix)
        if not path_downsample.is_file():  # only convert and save if needed
            image_grayscale = image.resize((downsample_size, downsample_size))
            image_grayscale.save(path_downsample)
        stimulus_set_downsample.image_paths[image_id] = path_downsample
    stimulus_set_downsample.identifier += '-downsample'
    return stimulus_set_downsample


def copy_paths(paths, target_directory, skip_if_exist=True):
    if target_directory.is_dir() and len(list(target_directory.iterdir())) == len(paths) and skip_if_exist:
        # files have already been copied
        return list(target_directory.iterdir())
    target_directory.mkdir(exist_ok=False)
    copied_paths = []
    for path in tqdm(paths, desc='copy paths'):
        target_path = target_directory / path.name
        shutil.copy(path, target_path)
        copied_paths.append(target_path)
    return copied_paths


def collect_assembly():
    # data extracted with https://apps.automeris.io/wpd/ on 2021-07-05, 300 color distance + manual fixes
    data = pd.read_csv(Path(__file__).parent / '100-150ms.csv')
    data = DataAssembly(data['psychometric_shift'], coords={
        'experiment_number': ('experiment', np.arange(len(data))),
        'face_selectivity': ('experiment', data['face_selectivity'])
    }, dims=['experiment'])
    return data


if __name__ == '__main__':
    train_stimulus_set, test_stimulus_set = train_test_stimuli()
